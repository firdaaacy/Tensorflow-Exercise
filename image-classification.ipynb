{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firdaaacy/Tensorflow-Exercise/blob/main/image-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1x3zvN2Tlio",
        "outputId": "ae24dd79-c4ef-49ed-c1be-40652b345e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "11/11 [==============================] - 109s 10s/step - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6842 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 103s 9s/step - loss: 0.6634 - accuracy: 0.6037 - val_loss: 0.5987 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 104s 9s/step - loss: 0.5784 - accuracy: 0.7176 - val_loss: 0.4315 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.5057 - accuracy: 0.7449 - val_loss: 0.3397 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 103s 10s/step - loss: 0.3896 - accuracy: 0.8238 - val_loss: 0.2833 - val_accuracy: 0.8945\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 98s 9s/step - loss: 0.3114 - accuracy: 0.8539 - val_loss: 0.3178 - val_accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 99s 9s/step - loss: 0.2766 - accuracy: 0.8822 - val_loss: 0.3021 - val_accuracy: 0.8906\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 107s 10s/step - loss: 0.2279 - accuracy: 0.9143 - val_loss: 0.3295 - val_accuracy: 0.9023\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 99s 9s/step - loss: 0.2144 - accuracy: 0.9094 - val_loss: 0.4353 - val_accuracy: 0.8867\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 99s 9s/step - loss: 0.2234 - accuracy: 0.9192 - val_loss: 0.3681 - val_accuracy: 0.9062\n"
          ]
        }
      ],
      "source": [
        "# =====================================================================================\n",
        "# PROBLEM A2 \n",
        "#\n",
        "# Build a Neural Network Model for Horse or Human Dataset.\n",
        "# The test will expect it to classify binary classes. \n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 83%\n",
        "# ======================================================================================\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def solution_A2():\n",
        "    data_url_1 = 'https://github.com/dicodingacademy/assets/releases/download/release-horse-or-human/horse-or-human.zip'\n",
        "    urllib.request.urlretrieve(data_url_1, 'horse-or-human.zip')\n",
        "    local_file = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/horse-or-human')\n",
        "\n",
        "    data_url_2 = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/validation-horse-or-human.zip'\n",
        "    urllib.request.urlretrieve(data_url_2, 'validation-horse-or-human.zip')\n",
        "    local_file = 'validation-horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/validation-horse-or-human')\n",
        "    zip_ref.close()\n",
        "\n",
        "    TRAINING_DIR = 'data/horse-or-human'\n",
        "    VALIDATION_DIR = 'data/validation-horse-or-human'\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1 / 255,\n",
        "                                      # width_shift_range=0.2,\n",
        "                                      # height_shift_range=0.2,\n",
        "                                      #  horizontal_flip=True,\n",
        "                                      #  zoom_range=0.25,\n",
        "                                      #  shear_range=0.25,\n",
        "                                      #  rotation_range=10,\n",
        "                                      #  fill_mode='nearest'\n",
        "                                       )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                        batch_size=100,\n",
        "                                                        class_mode='binary',\n",
        "                                                        shuffle=True,\n",
        "                                                        interpolation=\"bilinear\",\n",
        "                                                        target_size=(150, 150))\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1/255) \n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                             batch_size=100,\n",
        "                                                             class_mode='binary',\n",
        "                                                             shuffle=True,\n",
        "                                                             interpolation=\"bilinear\",\n",
        "                                                             target_size=(150, 150))\n",
        "\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dropout(rate=0.3),\n",
        "         tf.keras.layers.Dense(128, activation='relu'),\n",
        "         \n",
        "         tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "         ])\n",
        "    \n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_A2()\n",
        "    model.save(\"model_A2.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================================================\n",
        "# PROBLEM A3 \n",
        "#\n",
        "# Build a classifier for the Human or Horse Dataset with Transfer Learning. \n",
        "# The test will expect it to classify binary classes.\n",
        "# Note that all the layers in the pre-trained model are non-trainable.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The horse-or-human dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n",
        "# Inception_v3, pre-trained model used in this problem is developed by Google.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 93%.\n",
        "# =======================================================================================================\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "def solution_A3():\n",
        "    inceptionv3='https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "    urllib.request.urlretrieve(inceptionv3, 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "    local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "    pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "    pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "    for layer in pre_trained_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # last_layer = pre_trained_model.get_layer('mixed6')\n",
        "    last_output = pre_trained_model.output\n",
        "\n",
        "    # data_url_1 = 'https://github.com/dicodingacademy/assets/releases/download/release-horse-or-human/horse-or-human.zip'\n",
        "    # urllib.request.urlretrieve(data_url_1, 'horse-or-human.zip')\n",
        "    # local_file = 'horse-or-human.zip'\n",
        "    # zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    # zip_ref.extractall('data/horse-or-human')\n",
        "\n",
        "    # data_url_2 = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/validation-horse-or-human.zip'\n",
        "    # urllib.request.urlretrieve(data_url_2, 'validation-horse-or-human.zip')\n",
        "    # local_file = 'validation-horse-or-human.zip'\n",
        "    # zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    # zip_ref.extractall('data/validation-horse-or-human')\n",
        "    # zip_ref.close()\n",
        "\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "    local_zip = 'horse-or-human.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/horse-or-human/')\n",
        "    zip_ref.close()\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'testdata.zip')\n",
        "    local_zip = 'testdata.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/testdata/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    x = layers.Flatten()(last_output)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(pre_trained_model.input, x)\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
        "\n",
        "    model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "\n",
        "    train_dir = 'tmp/horse-or-human/'\n",
        "    validation_dir = 'tmp/testdata/'\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale =1/255,\n",
        "                                       fill_mode = 'nearest',\n",
        "                                       horizontal_flip = True,\n",
        "                                       rotation_range = 45,\n",
        "                                       width_shift_range=0.25,\n",
        "                                       height_shift_range=0.25,\n",
        "                                       shear_range=0.25,\n",
        "                                       zoom_range=0.25)\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                        batch_size=100,\n",
        "                                                        class_mode='binary',\n",
        "                                                        shuffle=True,\n",
        "                                                        interpolation='bilinear',\n",
        "                                                        target_size=(150, 150))\n",
        "    \n",
        "    validation_datagen = ImageDataGenerator(rescale=1/255) \n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                             batch_size=100,\n",
        "                                                             class_mode='binary',\n",
        "                                                             shuffle=True,\n",
        "                                                             interpolation='bilinear',\n",
        "                                                             target_size=(150, 150))\n",
        "    \n",
        "\n",
        "    model.fit(train_generator, validation_data=validation_generator, epochs=5, callbacks=[callbacks])\n",
        "    \n",
        "    # model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # model.fit(train_x, train_y, validation_data=(x_test, y_test), epochs=10, callbacks=[callbacks])\n",
        "\n",
        "    return model\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_A3()\n",
        "    model.save(\"model_A3.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0x-glnT1zbr",
        "outputId": "5cd597a3-5ef9-4a36-ed7c-a53050f29556"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "11/11 [==============================] - 70s 6s/step - loss: 1.9462 - acc: 0.7478 - val_loss: 0.0376 - val_acc: 0.9961\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.3452 - acc: 0.8793 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.1878 - acc: 0.9357 - val_loss: 0.0305 - val_acc: 1.0000\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.1064 - acc: 0.9659 - val_loss: 0.0153 - val_acc: 0.9961\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.1657 - acc: 0.9416 - val_loss: 0.0135 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBvQynIouU9i"
      },
      "source": [
        "SUBMISSION B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUrownmSB1RB",
        "outputId": "fdc08381-16f7-4f7b-ccf6-9e22de0f2741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 94s 1s/step - loss: 0.8611 - accuracy: 0.5962 - val_loss: 0.5359 - val_accuracy: 0.7004\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 82s 1s/step - loss: 0.1472 - accuracy: 0.9544 - val_loss: 0.3060 - val_accuracy: 0.8492\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0555 - accuracy: 0.9846 - val_loss: 0.4073 - val_accuracy: 0.8294\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0645 - accuracy: 0.9777 - val_loss: 0.3579 - val_accuracy: 0.7996\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 80s 1s/step - loss: 0.0381 - accuracy: 0.9891 - val_loss: 0.2494 - val_accuracy: 0.9107\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.1950 - val_accuracy: 0.9187\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.2457 - val_accuracy: 0.8869\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.1341 - val_accuracy: 0.9603\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 80s 1s/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.3617 - val_accuracy: 0.8849\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1755 - val_accuracy: 0.9425\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================================\n",
        "# PROBLEM B3\n",
        "#\n",
        "# Build a CNN based classifier for Rock-Paper-Scissors dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n",
        "#\n",
        "# Desired accuracy AND validation_accuracy > 83%\n",
        "# ========================================================================================\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# class MyCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         if (logs.get('val_accuracy') > 0.86 and logs.get('accuracy') > 0.83):\n",
        "#             print(\"\\nAccuracy and Validation Accuracy reached 83%, so cancelled training!\")\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "\n",
        "def solution_B3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/releases/download/release-rps/rps.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'rps.zip')\n",
        "    local_file = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    TRAINING_DIR = \"data/rps/\"\n",
        "    training_datagen = ImageDataGenerator(validation_split=0.2,\n",
        "                                          rescale=1 / 255,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          rotation_range=10,\n",
        "                                          fill_mode='nearest',\n",
        "                                          horizontal_flip=True\n",
        "                                          )\n",
        "\n",
        "    train_generator = training_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                           batch_size=32,\n",
        "                                                           class_mode=\"categorical\",\n",
        "                                                           subset=\"training\",\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(150, 150))\n",
        "\n",
        "    validation_generator = training_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode=\"categorical\",\n",
        "                                                                subset=\"validation\",\n",
        "                                                                target_size=(150, 150))\n",
        "\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "         tf.keras.layers.Dropout(0.3),\n",
        "         \n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "         tf.keras.layers.Dropout(0.2),\n",
        "         tf.keras.layers.Dense(3, activation=\"softmax\")\n",
        "         ])\n",
        "\n",
        "    # callbacks = MyCallback()\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_B3()\n",
        "    model.save(\"model_B3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV4wHgx5ITCe"
      },
      "source": [
        "PAKET C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-j1mUw2M_ZR",
        "outputId": "995d00df-9f07-448e-9299-a3c9a3b6b9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 126s 6s/step - loss: 0.8640 - accuracy: 0.5055 - val_loss: 0.6904 - val_accuracy: 0.5560\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 107s 5s/step - loss: 0.6960 - accuracy: 0.5235 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.6908 - accuracy: 0.5390 - val_loss: 0.8869 - val_accuracy: 0.5230\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.6972 - accuracy: 0.5755 - val_loss: 0.6581 - val_accuracy: 0.6310\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 104s 5s/step - loss: 0.6614 - accuracy: 0.5920 - val_loss: 0.6820 - val_accuracy: 0.5620\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.6706 - accuracy: 0.6050 - val_loss: 0.6963 - val_accuracy: 0.5400\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.6521 - accuracy: 0.6175 - val_loss: 0.6182 - val_accuracy: 0.6550\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 108s 5s/step - loss: 0.6450 - accuracy: 0.6370 - val_loss: 0.6292 - val_accuracy: 0.6500\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 108s 5s/step - loss: 0.6278 - accuracy: 0.6520 - val_loss: 0.6253 - val_accuracy: 0.6580\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.6316 - accuracy: 0.6510 - val_loss: 0.6501 - val_accuracy: 0.6280\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 108s 5s/step - loss: 0.6221 - accuracy: 0.6515 - val_loss: 0.6922 - val_accuracy: 0.6120\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 108s 5s/step - loss: 0.6302 - accuracy: 0.6600 - val_loss: 0.6152 - val_accuracy: 0.6690\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 109s 5s/step - loss: 0.6147 - accuracy: 0.6560 - val_loss: 0.5995 - val_accuracy: 0.6650\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 104s 5s/step - loss: 0.6048 - accuracy: 0.6740 - val_loss: 0.6722 - val_accuracy: 0.5620\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 104s 5s/step - loss: 0.6122 - accuracy: 0.6695 - val_loss: 0.5871 - val_accuracy: 0.6880\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 107s 5s/step - loss: 0.6081 - accuracy: 0.6545 - val_loss: 0.5939 - val_accuracy: 0.6650\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.5937 - accuracy: 0.6780 - val_loss: 0.6265 - val_accuracy: 0.6630\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.5803 - accuracy: 0.6765 - val_loss: 0.6048 - val_accuracy: 0.6590\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.6491 - accuracy: 0.6665 - val_loss: 0.6779 - val_accuracy: 0.6270\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 108s 5s/step - loss: 0.5694 - accuracy: 0.7030 - val_loss: 0.5877 - val_accuracy: 0.6610\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 104s 5s/step - loss: 0.5664 - accuracy: 0.7035 - val_loss: 0.6226 - val_accuracy: 0.6590\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.5878 - accuracy: 0.6925 - val_loss: 0.6647 - val_accuracy: 0.6150\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 109s 5s/step - loss: 0.5820 - accuracy: 0.6885 - val_loss: 0.5780 - val_accuracy: 0.6710\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.5669 - accuracy: 0.7005 - val_loss: 0.5648 - val_accuracy: 0.7190\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.5625 - accuracy: 0.7105 - val_loss: 0.5799 - val_accuracy: 0.6770\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 109s 5s/step - loss: 0.5556 - accuracy: 0.7130 - val_loss: 0.5971 - val_accuracy: 0.6850\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 104s 5s/step - loss: 0.5694 - accuracy: 0.7030 - val_loss: 0.6348 - val_accuracy: 0.6310\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 106s 5s/step - loss: 0.5571 - accuracy: 0.7130 - val_loss: 0.5821 - val_accuracy: 0.7050\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 105s 5s/step - loss: 0.5655 - accuracy: 0.7155 - val_loss: 0.5527 - val_accuracy: 0.7170\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 109s 5s/step - loss: 0.5471 - accuracy: 0.7210 - val_loss: 0.5410 - val_accuracy: 0.7060\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================================================\n",
        "# PROBLEM C3\n",
        "#\n",
        "# Build a CNN based classifier for Cats vs Dogs dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 72%\n",
        "# ========================================================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# class MyCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         if (logs.get('val_accuracy') > 0.73 and logs.get('accuracy') > 0.73):\n",
        "#             print(\"\\nAccuracy and Validation Accuracy reached 73%, so cancelled training!\")\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "\n",
        "def solution_C3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n",
        "    local_file = 'cats_and_dogs.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    BASE_DIR = 'data/cats_and_dogs_filtered'\n",
        "    train_dir = os.path.join(BASE_DIR, 'train')\n",
        "    validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1 / 255,\n",
        "                                       fill_mode='nearest',\n",
        "                                       horizontal_flip=True,\n",
        "                                       rotation_range=45,\n",
        "                                       width_shift_range=0.25,\n",
        "                                       height_shift_range=0.25,\n",
        "                                       shear_range=0.2,\n",
        "                                       zoom_range=0.2\n",
        "\n",
        "                                       )  # YOUR CODE HERE\n",
        "\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        rescale=1 / 255.0\n",
        "    )\n",
        "\n",
        "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "    # Make sure you used \"categorical\"\n",
        "    train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                        batch_size=100,\n",
        "                                                        class_mode='binary',\n",
        "                                                        shuffle=True,\n",
        "                                                        target_size=(150, 150))\n",
        "\n",
        "    val_generator = train_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                      batch_size=100,\n",
        "                                                      class_mode='binary',\n",
        "                                                      shuffle=True,\n",
        "                                                      target_size=(150, 150)\n",
        "\n",
        "                                                      )  # YOUR CODE HERE\n",
        "\n",
        "    # model = tf.keras.models.Sequential([\n",
        "    #     # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n",
        "    #     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    # ])\n",
        "\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "         tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        #  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        #  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        #  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        #  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        #  tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "         tf.keras.layers.Flatten(),\n",
        "         # tf.keras.layers.Dense(128, activation='relu'),\n",
        "         tf.keras.layers.Dense(64, activation='relu'),\n",
        "        #  tf.keras.layers.Dropout(0.3),\n",
        "         # # YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n",
        "         tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "         ])\n",
        "\n",
        "    # callbacks = MyCallback()\n",
        "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.fit(train_generator, validation_data=val_generator, epochs=30)\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C3()\n",
        "    model.save(\"model_C3.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNt7+gG8IpMD3p5oIBdmf9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}